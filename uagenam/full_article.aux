\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand{\transparent@use}[1]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{Lin_2014}
\citation{Burns_2015}
\citation{how_expression_works}
\citation{Krizhevsky2012ImageNetCW}
\citation{Lin_2014}
\citation{Burns_2015}
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{5}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{5}{section.2}}
\citation{Imaizumi2014ModelingHN}
\citation{Lancaster_2014}
\citation{nguyen_wang_nikolakopoulou_2015}
\citation{nguyen_wang_nikolakopoulou_2015}
\citation{nguyen_wang_nikolakopoulou_2015}
\@writefile{toc}{\contentsline {section}{\numberline {3}Literature review}{6}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Neurological disease modeling}{6}{subsection.3.1}}
\citation{neural_development}
\citation{neural_development}
\citation{Bakken_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A cerebral organoid viewed under fluorescence microscopy \citep  {nguyen_wang_nikolakopoulou_2015}.\relax }}{7}{figure.caption.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Brain development}{7}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Development of the neural tube \citep  {neural_development}. \relax }}{8}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:development}{{2}{8}{Development of the neural tube \citep {neural_development}. \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Gene expression regulation}{8}{subsection.3.3}}
\newlabel{regulation}{{3.3}{8}{Gene expression regulation}{subsection.3.3}{}}
\citation{bisceglia_2010}
\citation{bisceglia_2010}
\citation{bisceglia_2010}
\citation{Angerer_1991}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Gene expression measurement}{9}{subsection.3.4}}
\citation{Wang_2009}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {A.} A general overview of the flow of information from DNA to RNA to protein. \textbf  {B.} Demonstration of cell differentiation \citep  {bisceglia_2010}.\relax }}{10}{figure.caption.5}}
\citation{how_expression_works}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An ISH stain for glial fibrillary acidic protein (GFAP) RNA in the P14 mouse brain. At left is a diagram of the regions shown in the staining for reference (Allen Brain Atlas). \relax }}{11}{figure.caption.6}}
\newlabel{fig:ish}{{4}{11}{An ISH stain for glial fibrillary acidic protein (GFAP) RNA in the P14 mouse brain. At left is a diagram of the regions shown in the staining for reference (Allen Brain Atlas). \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Gene expression analysis}{11}{subsection.3.5}}
\newlabel{gene_analysis}{{3.5}{11}{Gene expression analysis}{subsection.3.5}{}}
\citation{leukemia_clustering}
\citation{leukemia_clustering}
\citation{Thompson_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An example of a clustering algorithm applied to expression values of genes related to acute myeloid leukemia. Dendrograms were created for regions (top) and sample (left) \citep  {leukemia_clustering}. \relax }}{12}{figure.caption.7}}
\newlabel{fig:leukemia}{{5}{12}{An example of a clustering algorithm applied to expression values of genes related to acute myeloid leukemia. Dendrograms were created for regions (top) and sample (left) \citep {leukemia_clustering}. \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}The Allen Brain Atlas}{12}{subsection.3.6}}
\citation{24695229}
\citation{Zilouchian2001FundamentalsON}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Neural networks}{13}{subsection.3.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A heatmap of expression values for the Abelson murine leukemia viral oncogene homolog 1 (ABL1) gene in the developing mouse brain. Expression values were obtained from ISH stains and computed for each region using specialized 3-D voxel counts provided by the Allen Brain Atlas API. The y-axis is the development stage and the x-axis is the brain region (abbreviated). The expression values were transformed to a logarithmic scale to account for skew. \relax }}{14}{figure.caption.8}}
\newlabel{fig:matrix}{{6}{14}{A heatmap of expression values for the Abelson murine leukemia viral oncogene homolog 1 (ABL1) gene in the developing mouse brain. Expression values were obtained from ISH stains and computed for each region using specialized 3-D voxel counts provided by the Allen Brain Atlas API. The y-axis is the development stage and the x-axis is the brain region (abbreviated). The expression values were transformed to a logarithmic scale to account for skew. \relax }{figure.caption.8}{}}
\citation{Zilouchian2001FundamentalsON}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A diagram of a basic neuron with input values $x_{1}$,$x_{2}$, and $x_{3}$ with respective weights $w_{1}$,$w_{2}$, and $w_{3}$ and a bias $b$. The neuron computes the sum of these inputs and outputs a value $y$ determined by activation function $f$. \relax }}{15}{figure.caption.9}}
\newlabel{fig:neuron}{{7}{15}{A diagram of a basic neuron with input values $x_{1}$,$x_{2}$, and $x_{3}$ with respective weights $w_{1}$,$w_{2}$, and $w_{3}$ and a bias $b$. The neuron computes the sum of these inputs and outputs a value $y$ determined by activation function $f$. \relax }{figure.caption.9}{}}
\citation{Zilouchian2001FundamentalsON}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Graphs of common neuron activation functions.\relax }}{16}{figure.caption.10}}
\newlabel{fig:activations}{{8}{16}{Graphs of common neuron activation functions.\relax }{figure.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Equations of the activation functions shown in Figure~\ref  {fig:activations}.\relax }}{16}{table.caption.11}}
\newlabel{table:1}{{1}{16}{Equations of the activation functions shown in Figure~\ref {fig:activations}.\relax }{table.caption.11}{}}
\citation{Krizhevsky2012ImageNetCW}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces An example neural network that learns to generate an image given x and y pixel position inputs. The inputs are the x and y coordinates of the pixel, and the outputs are the three red-green-blue (RGB) values that define the color of a pixel.  \relax }}{17}{figure.caption.12}}
\newlabel{fig:doodle}{{9}{17}{An example neural network that learns to generate an image given x and y pixel position inputs. The inputs are the x and y coordinates of the pixel, and the outputs are the three red-green-blue (RGB) values that define the color of a pixel.  \relax }{figure.caption.12}{}}
\citation{Koushik2016UnderstandingCN}
\citation{peemen_mesman_corporaal_2011}
\citation{peemen_mesman_corporaal_2011}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces An example of a simple convolutional network designed for digit classification of the MNIST dataset. \relax }}{18}{figure.caption.13}}
\newlabel{fig:convolutional_mnist}{{10}{18}{An example of a simple convolutional network designed for digit classification of the MNIST dataset. \relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces An example of a multi-layer CNN for classifying handwritten digits from the MNIST dataset. The feature extraction section repeatedly convolves the input image to higher level features, which are fed as inputs to the classification stage. In this case, the classification stage is composed of two fully connected layers, with the final layer outputting the predicted digit classification \citep  {peemen_mesman_corporaal_2011}. \relax }}{18}{figure.caption.14}}
\newlabel{fig:mnist_full}{{11}{18}{An example of a multi-layer CNN for classifying handwritten digits from the MNIST dataset. The feature extraction section repeatedly convolves the input image to higher level features, which are fed as inputs to the classification stage. In this case, the classification stage is composed of two fully connected layers, with the final layer outputting the predicted digit classification \citep {peemen_mesman_corporaal_2011}. \relax }{figure.caption.14}{}}
\citation{yangCVPR2016joint}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Unsupervised learning}{19}{subsection.3.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces An illustration of the primary difference between supervised (\textbf  {A}) and unsupervised (\textbf  {B}) learning. \relax }}{19}{figure.caption.15}}
\newlabel{fig:super}{{12}{19}{An illustration of the primary difference between supervised (\textbf {A}) and unsupervised (\textbf {B}) learning. \relax }{figure.caption.15}{}}
\citation{laurensvandermaaten2014}
\citation{laurensvandermaaten2014}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The results of a t-Distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction on a clustering of the MNIST (\textbf  {A}) and CIFAR-10 (\textbf  {B}) datasets \citep  {laurensvandermaaten2014}. \relax }}{20}{figure.caption.16}}
\newlabel{fig:clusters}{{13}{20}{The results of a t-Distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction on a clustering of the MNIST (\textbf {A}) and CIFAR-10 (\textbf {B}) datasets \citep {laurensvandermaaten2014}. \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Research plan}{20}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Researchable question}{20}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Hypothesis}{20}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Procedure}{20}{subsection.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methodology}{21}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Overall workflow}{21}{subsection.5.1}}
\citation{tensorflow2015-whitepaper}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The overall process involved in this project. \relax }}{22}{figure.caption.17}}
\newlabel{fig:workflow}{{14}{22}{The overall process involved in this project. \relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Software}{22}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Data retrieval}{23}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Data pre-processing}{23}{subsection.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Comparison between (\textbf  {A}) raw expression values and (\textbf  {B}) log2-transformed expression values for each region between the human (top) and mouse (bottom) datasets. \relax }}{24}{figure.caption.18}}
\newlabel{fig:log2}{{15}{24}{Comparison between (\textbf {A}) raw expression values and (\textbf {B}) log2-transformed expression values for each region between the human (top) and mouse (bottom) datasets. \relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Machine learning model}{24}{subsection.5.5}}
\citation{Maaten2008VisualizingDU}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces CAE architectures used for dimensionality reduction of the mouse (\textbf  {A}) and human (\textbf  {B}) datasets. Green sections indicate convolutional layers involved in the encoding process, and purple sections indicate the encoded dense (fully connected) network. Blue sections indicate layers involved in the decoding process. The layer indicated in orange is the four-dimensional layer that is extracted upon training. The dimensions of each layer are shown below the respective layer. \relax }}{26}{figure.caption.19}}
\newlabel{fig:CAE}{{16}{26}{CAE architectures used for dimensionality reduction of the mouse (\textbf {A}) and human (\textbf {B}) datasets. Green sections indicate convolutional layers involved in the encoding process, and purple sections indicate the encoded dense (fully connected) network. Blue sections indicate layers involved in the decoding process. The layer indicated in orange is the four-dimensional layer that is extracted upon training. The dimensions of each layer are shown below the respective layer. \relax }{figure.caption.19}{}}
\citation{Bishoplearning}
\citation{Ester1996ADA}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Cluster identification}{28}{subsection.5.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Clustering comparison}{28}{subsection.5.7}}
\citation{Zhang2010ARImpAG}
\citation{Zhang2010ARImpAG}
\citation{Yeung2001DetailsOT}
\bibstyle{apa}
\bibdata{bibliography/biblio.bib}
\bibcite{tensorflow2015-whitepaper}{{1}{2015}{{Abadi et~al.}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The contingency matrix used in computing the ARI between two clusterings $k$ and $h$. \citep  {Zhang2010ARImpAG}\relax }}{29}{table.caption.20}}
\newlabel{table:2}{{2}{29}{The contingency matrix used in computing the ARI between two clusterings $k$ and $h$. \citep {Zhang2010ARImpAG}\relax }{table.caption.20}{}}
\bibcite{Angerer_1991}{{2}{1991}{{Angerer and Angerer}}{{}}}
\bibcite{Bakken_2015}{{3}{2015}{{Bakken et~al.}}{{}}}
\bibcite{bisceglia_2010}{{4}{2010}{{Bisceglia}}{{}}}
\bibcite{Bishoplearning}{{5}{2006}{{Bishop}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{30}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{30}{section.7}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusions}{30}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Limitations}{30}{section.9}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Extensions}{30}{section.10}}
\bibcite{Burns_2015}{{6}{2015}{{Burns et~al.}}{{}}}
\bibcite{how_expression_works}{{7}{2005}{{D'haeseleer}}{{}}}
\bibcite{Ester1996ADA}{{8}{}{{Ester et~al.}}{{}}}
\bibcite{Imaizumi2014ModelingHN}{{9}{2014}{{Imaizumi and Okano}}{{}}}
\bibcite{Koushik2016UnderstandingCN}{{10}{2016}{{Koushik}}{{}}}
\bibcite{Krizhevsky2012ImageNetCW}{{11}{2012}{{Krizhevsky et~al.}}{{}}}
\bibcite{Lancaster_2014}{{12}{2014}{{Lancaster and Knoblich}}{{}}}
\bibcite{Lin_2014}{{13}{2014}{{Lin et~al.}}{{}}}
\bibcite{Maaten2008VisualizingDU}{{14}{2008}{{Maaten and Hinton}}{{}}}
\bibcite{24695229}{{15}{2014}{{Miller et~al.}}{{}}}
\bibcite{leukemia_clustering}{{16}{2004}{{Muller-Tidow et~al.}}{{}}}
\bibcite{nguyen_wang_nikolakopoulou_2015}{{17}{2015}{{Nguyen et~al.}}{{}}}
\bibcite{peemen_mesman_corporaal_2011}{{18}{2011}{{Peemen et~al.}}{{}}}
\bibcite{neural_development}{{19}{2015}{{Sim{\~o}es-Costa and Bronner}}{{}}}
\bibcite{Thompson_2014}{{20}{2014}{{Thompson et~al.}}{{}}}
\bibcite{laurensvandermaaten2014}{{21}{2014}{{van~der Maaten}}{{}}}
\bibcite{Wang_2009}{{22}{2009}{{Wang et~al.}}{{}}}
\bibcite{yangCVPR2016joint}{{23}{2016}{{Yang et~al.}}{{}}}
\bibcite{Yeung2001DetailsOT}{{24}{2001}{{Yeung and Ruzzo}}{{}}}
\bibcite{Zhang2010ARImpAG}{{25}{2010}{{Zhang and Wong}}{{}}}
\bibcite{Zilouchian2001FundamentalsON}{{26}{2001}{{Zilouchian}}{{}}}
